{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "root_path = os.path.join(\"event\")\n",
    "result_path = os.path.join(\"event_drug_symptom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_year = {\n",
    "            '800': 10,          # decade\n",
    "            '801': 1,           # year\n",
    "            '802': 1 / 12,      # month\n",
    "            '803': 1 / (12 * 4),# week\n",
    "            '804': 1 / 365,     # days\n",
    "            '805': 1 / 8760,    # hour\n",
    "        }\n",
    "decode_sex = {0: 'unknown', 1: \"Male\", 2: \"Female\"}\n",
    "\n",
    "decode_characterization = {\n",
    "            1: \"Suspect (the drug was considered by the reporter to be the cause)\",\n",
    "            2: \"Concomitant (the drug was reported as being taken along with the suspect drug)\",\n",
    "            3: \"Interacting (the drug was considered by the reporter to have interacted with the suspect drug)\"\n",
    "        }\n",
    "decode_serious = {\n",
    "            1: \"The adverse event resulted in death, a life threatening condition, hospitalization, disability, \\\n",
    "            congenital anomaly, or other serious condition\",\n",
    "            2: \"The adverse event did not result in any of the above\"}\n",
    "decode_death = {\n",
    "            0: \"survive\",\n",
    "            1: \"death\"\n",
    "        }\n",
    "decode_sender = {\n",
    "            1: \"Physician\",\n",
    "            2: \"Pharmacist\",\n",
    "            3: \"Other health professional\",\n",
    "            4: \"Lawyer\",\n",
    "            5: \"Consumer or non-health professional\",\n",
    "            0: \"unknown\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from download.py with modification\n",
    "def download(arg):\n",
    "    \"\"\"download file at url and save at dir \"\"\"\n",
    "    url, directory = arg\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(directory, 'wb').write(r.content)\n",
    "    with zipfile.ZipFile(directory, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(directory))\n",
    "    os.remove(directory)\n",
    "\n",
    "def get_event_links(path):\n",
    "    \"\"\"obtain all download links for events from fdc's provided download json\"\"\"\n",
    "    with open(path, 'r') as handle:\n",
    "        file = json.load(handle)\n",
    "    events = file['results'][\"drug\"][\"event\"]\n",
    "    links = []\n",
    "    for p in events['partitions']:\n",
    "        links.append(p['file'])\n",
    "    return links\n",
    "\n",
    "def get_ndc_links(path):\n",
    "    \"\"\"obtain all download links for events from fdc's provided download json\"\"\"\n",
    "    with open(path, 'r') as handle:\n",
    "        file = json.load(handle)\n",
    "    events = file['results'][\"drug\"][\"ndc\"]\n",
    "    links = []\n",
    "    for p in events['partitions']:\n",
    "        links.append(p['file'])\n",
    "    return links\n",
    "\n",
    "links = get_event_links(\"download.json\")\n",
    "ndc_links = get_ndc_links(\"download.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ndc file\n",
    "url = ndc_links[0]\n",
    "infos = url.split(\"/\")[3:] # getting rid of https and website\n",
    "path = ''\n",
    "for i in infos:\n",
    "    path = os.path.join(path, i)\n",
    "    if i.endswith('.zip'):\n",
    "        break\n",
    "    else:\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        path = path.strip(\"\\n\")\n",
    "        url = url.strip(\"\\n\")\n",
    "download([url, path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21099it [00:00, 2350731.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a symptom database from symptoms.json\"\"\"\n",
    "\n",
    "symptoms = json.load(open(\"symptoms.json\", \"r\"))\n",
    "data = {\"id\":[], \"symptom\":[]}\n",
    "for i, ele in tqdm(enumerate(symptoms)):\n",
    "    data[\"id\"].append(i)\n",
    "    data[\"symptom\"].append(ele)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(\"drug\",\"symptoms_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126701it [00:00, 456978.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create datasets for ndc's drug listings and their active ingredients\"\"\" \n",
    "\"\"\"id is associated with the brand_name\"\"\"\n",
    "\n",
    "ndc_data = {\"id\":[], \"brand_name\":[], \"generic_name\":[], \"product_type\":[], \"manufacturer_name\":[]}\n",
    "components = {\"id\":[], \"active_ingredient\":[]}\n",
    "\n",
    "encode_product_type = {\"HUMAN OTC DRUG\":0, \n",
    "                       \"HUMAN PRESCRIPTION DRUG\":1, \n",
    "                       \"PLASMA DERIVATIVE\":2, \n",
    "                       \"VACCINE\":3, \n",
    "                       \"BULK INGREDIENT\":4, \n",
    "                       \"DRUG FOR FURTHER PROCESSING\":5, \n",
    "                       \"CELLULAR THERAPY\":6, \n",
    "                       \"LICENSED VACCINE BULK INTERMEDIATE\":7,\n",
    "                       \"STANDARDIZED ALLERGENIC\":8, \"NON-STANDARDIZED ALLERGENIC\":9}\n",
    "\n",
    "with open(os.path.join(\"ndc\", \"drug-ndc-0001-of-0001.json\")) as ifs:\n",
    "    ndc = json.load(ifs)\n",
    "    ndc = ndc[\"results\"] # list of dict\n",
    "    for i, ele in tqdm(enumerate(ndc)):\n",
    "        if \"generic_name\" in ele:\n",
    "            for name in ele[\"generic_name\"].split(\",\"):\n",
    "                ndc_data[\"id\"].append(i)\n",
    "                ndc_data[\"generic_name\"].append(name.strip())\n",
    "                ndc_data[\"brand_name\"].append(ele[\"brand_name_base\"])\n",
    "                ndc_data[\"product_type\"].append(encode_product_type[ele[\"product_type\"]])\n",
    "                if \"manufacturer_name\" in ele[\"openfda\"]:\n",
    "                    ndc_data[\"manufacturer_name\"].append(ele[\"openfda\"][\"manufacturer_name\"][0])\n",
    "                else:\n",
    "                    ndc_data[\"manufacturer_name\"].append(\"__NULL__\")\n",
    "        else:\n",
    "            ndc_data[\"id\"].append(i)\n",
    "            ndc_data[\"generic_name\"].append(\"__NULL__\")\n",
    "            ndc_data[\"brand_name\"].append(ele[\"brand_name_base\"])\n",
    "            ndc_data[\"product_type\"].append(encode_product_type[ele[\"product_type\"]])\n",
    "            if \"manufacturer_name\" in ele[\"openfda\"]:\n",
    "                ndc_data[\"manufacturer_name\"].append(ele[\"openfda\"][\"manufacturer_name\"][0])\n",
    "            else:\n",
    "                ndc_data[\"manufacturer_name\"].append(\"__NULL__\")\n",
    "        if \"active_ingredients\" in ele:\n",
    "            for comp in ele[\"active_ingredients\"]:\n",
    "                components[\"id\"].append(i)\n",
    "                components[\"active_ingredient\"].append(comp[\"name\"])\n",
    "    ndc_df = pd.DataFrame(ndc_data)\n",
    "    ndc_df.to_csv(os.path.join(\"drug\",\"drug_dataset.csv\"), index=False)\n",
    "    comp_df = pd.DataFrame(components)\n",
    "    comp_df.to_csv(os.path.join(\"drug\",\"active_ingredient_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205412it [00:12, 16003.20it/s]\n",
      "21099it [00:01, 16038.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Drug and Symptom Reverse Lookup\"\"\"\n",
    "\n",
    "#Brand_Name -> ID\n",
    "drug_vocab = {}\n",
    "drug_df = pd.read_csv(os.path.join(\"drug\",\"drug_dataset.csv\"))\n",
    "for i,row in tqdm(drug_df.iterrows()):\n",
    "    drug_vocab[row[\"brand_name\"]] = row[\"id\"]\n",
    "\n",
    "# Keep track of discovered drugs\n",
    "num_drugs = len(drug_df)\n",
    "missing_vocab = {}\n",
    "missing_drugs = {\"id\":[], \"brand_name\":[]}\n",
    "\n",
    "# Symptom -> ID\n",
    "symptom_vocab = {}\n",
    "symptom_df = pd.read_csv(os.path.join(\"drug\",\"symptoms_dataset.csv\"))\n",
    "symptom_df['symptom'] = symptom_df['symptom'].str.lower()\n",
    "for i,row in tqdm(symptom_df.iterrows()):\n",
    "    symptom_vocab[row[\"symptom\"]] = row[\"id\"]\n",
    "    \n",
    "event_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"drug\",\"events\")):\n",
    "    os.mkdir(os.path.join(\"drug\",\"events\"))\n",
    "    os.mkdir(os.path.join(\"drug\",\"drugs\"))\n",
    "    os.mkdir(os.path.join(\"drug\",\"characteristics\"))\n",
    "    os.mkdir(os.path.join(\"drug\",\"symptoms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [1:56:24, 19.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Drug Dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off drug_dataset\n",
    "    # missing list based off missing_dataset\n",
    "# Characterization dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off drug_dataset\n",
    "    # missing list based off missing_dataset\n",
    "# Symptoms dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off symptoms_dataset\n",
    "\n",
    "for link_index, url in tqdm(enumerate(links)):\n",
    "    # Download an event file\n",
    "    infos = url.split(\"/\")[3:] # getting rid of https and website\n",
    "    path = ''\n",
    "    for i in infos:\n",
    "        path = os.path.join(path, i)\n",
    "        if i.endswith('.zip'):\n",
    "            break\n",
    "        else:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            path = path.strip(\"\\n\")\n",
    "            url = url.strip(\"\\n\")\n",
    "    download([url, path])\n",
    "\n",
    "    folder_name = path.split(\"\\\\\")[-2]\n",
    "    file_name = path.split(\".\")[0]\n",
    "    split_name = file_name.split(\"\\\\\")[-1]\n",
    "\n",
    "    # Grab and decode events\n",
    "    events = json.load(open(file_name+\".json\", \"r\"))\n",
    "    events = events[\"results\"]\n",
    "\n",
    "    # Event Dataset:\n",
    "    event_data = {\"ID\":[], \"sex\":[], \"age\":[], \"serious\":[], \"death\":[], \"sender\":[], \"time\":[]}\n",
    "    drug_data = {\"ID\":[], \"postings\":[], \"missing\":[]}\n",
    "    char_data = {\"ID\":[], \"postings\":[], \"missing\":[]}\n",
    "    symp_data = {\"ID\":[], \"postings\":[]}\n",
    "\n",
    "    for event in events:\n",
    "        patient = event[\"patient\"]\n",
    "\n",
    "        # Event\n",
    "        event_data[\"ID\"].append(event_id)\n",
    "        event_data[\"serious\"].append(event[\"serious\"])\n",
    "\n",
    "        if \"patientsex\" in patient:\n",
    "            event_data[\"sex\"].append(decode_sex[int(patient['patientsex'])])\n",
    "        else:\n",
    "            event_data[\"sex\"].append(0)\n",
    "        try:\n",
    "            event_data[\"age\"].append(int(patient[\"patientonsetage\"]) * to_year[patient[\"patientonsetageunit\"]])\n",
    "        except:\n",
    "            event_data[\"age\"].append(-1)\n",
    "        if \"seriousnessdeath\" in event:\n",
    "            event_data[\"death\"].append(1)\n",
    "        else:\n",
    "            event_data[\"death\"].append(0)\n",
    "        try:\n",
    "            event_data[\"sender\"].append(decode_sender[int(event[\"primarysource\"][\"qualification\"])])\n",
    "        except:\n",
    "            event_data[\"sender\"].append(0)\n",
    "        try:\n",
    "            time = event['receiptdate']\n",
    "            timestamp = datetime.datetime(int(time[0:4]), int(time[4:6]), int(time[6::]), 0, 0).timestamp()\n",
    "            event_data[\"time\"].append(timestamp)\n",
    "        except:\n",
    "            event_data[\"time\"].append(-1)\n",
    "\n",
    "        # Drugs & Characteristics\n",
    "        drug_data[\"ID\"].append(event_id)\n",
    "        char_data[\"ID\"].append(event_id)\n",
    "        d = []\n",
    "        c = []\n",
    "        m_d = []\n",
    "        m_c = []\n",
    "        for ele in patient[\"drug\"]:\n",
    "            if \"medicinalproduct\" in ele:\n",
    "                # Check if drug in ndc data\n",
    "                if ele[\"medicinalproduct\"] in drug_vocab:\n",
    "                    d.append(drug_vocab[ele[\"medicinalproduct\"]])\n",
    "                    if \"drugcharacterization\" in ele: \n",
    "                        c.append(ele[\"drugcharacterization\"])\n",
    "                    else:\n",
    "                        c.append(0)\n",
    "                else:\n",
    "                    # Check if this missing drug has been seen before\n",
    "                    if ele[\"medicinalproduct\"] not in missing_vocab:\n",
    "                        missing_drugs[\"id\"].append(num_drugs)\n",
    "                        missing_drugs[\"brand_name\"].append(ele[\"medicinalproduct\"])\n",
    "                        missing_vocab[ele[\"medicinalproduct\"]] = num_drugs\n",
    "                        num_drugs += 1\n",
    "                    m_d.append(missing_vocab[ele[\"medicinalproduct\"]])                        \n",
    "                    if \"drugcharacterization\" in ele:\n",
    "                        m_c.append(ele[\"drugcharacterization\"])\n",
    "                    else:\n",
    "                        m_c.append(0)\n",
    "                \n",
    "        drug_data[\"postings\"].append(\" \".join([str(x) for x in d]))\n",
    "        char_data[\"postings\"].append(\" \".join([str(x) for x in c]))\n",
    "        drug_data[\"missing\"].append(\" \".join([str(x) for x in m_d]))\n",
    "        char_data[\"missing\"].append(\" \".join([str(x) for x in m_c]))\n",
    "\n",
    "        # Symptoms\n",
    "        symp_data[\"ID\"].append(event_id)\n",
    "        if \"reaction\" in patient:\n",
    "            s = []\n",
    "            for sym in patient[\"reaction\"]:\n",
    "                if \"reactionmeddrapt\" in sym:\n",
    "                    s.append(str(symptom_vocab[sym['reactionmeddrapt'].lower()]))\n",
    "            symp_data[\"postings\"].append(\" \".join(s))\n",
    "        else:\n",
    "            symp_data[\"postings\"].append(\"\")\n",
    "\n",
    "        event_id += 1\n",
    "\n",
    "    # Remove download\n",
    "    os.remove(file_name+\".json\")\n",
    "    os.rmdir(os.path.join(\"\\\\\".join(path.split(\"\\\\\")[0:3])))\n",
    "\n",
    "    # Write results to file\n",
    "    if not os.path.exists(os.path.join(\"drug\",\"events\", folder_name)):\n",
    "        os.mkdir(os.path.join(\"drug\",\"events\", folder_name))\n",
    "        os.mkdir(os.path.join(\"drug\",\"drugs\", folder_name))\n",
    "        os.mkdir(os.path.join(\"drug\",\"characteristics\", folder_name))\n",
    "        os.mkdir(os.path.join(\"drug\",\"symptoms\", folder_name))\n",
    "\n",
    "    event_df = pd.DataFrame(event_data)\n",
    "    event_df.to_csv(os.path.join(\"drug\", \"events\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    drug_df = pd.DataFrame(drug_data)\n",
    "    drug_df.to_csv(os.path.join(\"drug\", \"drugs\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    char_df = pd.DataFrame(char_data)\n",
    "    char_df.to_csv(os.path.join(\"drug\", \"characteristics\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    symp_df = pd.DataFrame(symp_data)\n",
    "    symp_df.to_csv(os.path.join(\"drug\", \"symptoms\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "missing_df = pd.DataFrame(missing_drugs)\n",
    "missing_df.to_csv(os.path.join(\"drug\",\"missing_drugs_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num missing: 614669\n",
      "num events: 10432358\n"
     ]
    }
   ],
   "source": [
    "print(\"num missing:\", len(missing_drugs[\"brand_name\"]))\n",
    "print(\"num events:\", event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [01:57<00:00,  5.30s/it]\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "check = False\n",
    "for folder in tqdm(os.listdir(os.path.join(\"drug\", \"drugs\"))):\n",
    "    for file in os.listdir(os.path.join(\"drug\", \"drugs\", folder)):\n",
    "        if check:\n",
    "            df = pd.concat([df, pd.read_csv(os.path.join(\"drug\", \"drugs\", folder, file))])\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(\"drug\", \"drugs\", folder, file))\n",
    "            check = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360690\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(\"\")\n",
    "subset = df.loc[df[\"missing\"]==\"\"]\n",
    "subset = subset.loc[subset[\"postings\"]!=\"\"]\n",
    "subset = subset[[\"ID\",\"postings\"]]\n",
    "print(len(subset))\n",
    "subset.to_csv(os.path.join(\"drug\",\"no_missing_drugs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\sjray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\sjray\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1015: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc[key] = value\n",
      "C:\\Users\\sjray\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "6it [00:10,  1.72s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_with_engine\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drug_count'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drug_count'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(key, value)\u001b[0m\n\u001b[0;32m    986\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_with_engine\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'drug_count'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-18b11fbe297c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"drug_count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"postings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"missing_count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"missing\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1037\u001b[0m         \u001b[1;31m# do the setitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(key, value)\u001b[0m\n\u001b[0;32m   1013\u001b[0m                             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1016\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    420\u001b[0m                     self.obj._data = self.obj._constructor(\n\u001b[0;32m    421\u001b[0m                         new_values, index=new_index, name=self.obj.name)._data\n\u001b[1;32m--> 422\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverify_is_copy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3144\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'referant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclear\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[1;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[0;32m   3244\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3246\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3247\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3248\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df2 = df\n",
    "df2 = df2.fillna(\"\")\n",
    "for i, row in tqdm(df2.iterrows()):\n",
    "    df2.iloc[i][\"drug_count\"] = len(row[\"postings\"].split(\" \"))\n",
    "    df2.iloc[i][\"missing_count\"] = len(row[\"missing\"].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10432358.0\n",
      "10432358.0\n",
      "0    10432358\n",
      "1    10432358\n",
      "2    10432358\n",
      "3    10432358\n",
      "4    10432358\n",
      "5    10432358\n",
      "6    10432358\n",
      "7    10432358\n",
      "8    10432358\n",
      "9    10432358\n",
      "Name: drug_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df2[\"drug_count\"].mean())\n",
    "print(df2[\"missing_count\"].mean())\n",
    "print(df2[\"drug_count\"].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614669\n",
      "447739\n",
      "443797\n"
     ]
    }
   ],
   "source": [
    "ms = pd.read_csv(os.path.join(\"drug\",\"missing_drugs_dataset.csv\"))\n",
    "miss = ms[\"brand_name\"].values\n",
    "miss = [str(x).lower().split(\"(\")[0].strip() for x in miss]\n",
    "print(len(miss))\n",
    "test = list(set(miss))\n",
    "print(len(test))\n",
    "test = [x for x in test if \"unknown\" not in x]\n",
    "print(len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
