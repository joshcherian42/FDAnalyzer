{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import zipfile\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "root_path = os.path.join(\"event\")\n",
    "result_path = os.path.join(\"event_drug_symptom\")\n",
    "drug_path = os.path.join(\"drug_brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_year = {\n",
    "            '800': 10,          # decade\n",
    "            '801': 1,           # year\n",
    "            '802': 1 / 12,      # month\n",
    "            '803': 1 / (12 * 4),# week\n",
    "            '804': 1 / 365,     # days\n",
    "            '805': 1 / 8760,    # hour\n",
    "        }\n",
    "decode_sex = {0: 'unknown', 1: \"Male\", 2: \"Female\"}\n",
    "\n",
    "decode_characterization = {\n",
    "            1: \"Suspect (the drug was considered by the reporter to be the cause)\",\n",
    "            2: \"Concomitant (the drug was reported as being taken along with the suspect drug)\",\n",
    "            3: \"Interacting (the drug was considered by the reporter to have interacted with the suspect drug)\"\n",
    "        }\n",
    "decode_serious = {\n",
    "            1: \"The adverse event resulted in death, a life threatening condition, hospitalization, disability, \\\n",
    "            congenital anomaly, or other serious condition\",\n",
    "            2: \"The adverse event did not result in any of the above\"}\n",
    "decode_death = {\n",
    "            0: \"survive\",\n",
    "            1: \"death\"\n",
    "        }\n",
    "decode_sender = {\n",
    "            1: \"Physician\",\n",
    "            2: \"Pharmacist\",\n",
    "            3: \"Other health professional\",\n",
    "            4: \"Lawyer\",\n",
    "            5: \"Consumer or non-health professional\",\n",
    "            0: \"unknown\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from download.py with modification\n",
    "def download(arg):\n",
    "    \"\"\"download file at url and save at dir \"\"\"\n",
    "    url, directory = arg\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(directory, 'wb').write(r.content)\n",
    "    with zipfile.ZipFile(directory, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.dirname(directory))\n",
    "    os.remove(directory)\n",
    "\n",
    "def get_event_links(path):\n",
    "    \"\"\"obtain all download links for events from fdc's provided download json\"\"\"\n",
    "    with open(path, 'r') as handle:\n",
    "        file = json.load(handle)\n",
    "    events = file['results'][\"drug\"][\"event\"]\n",
    "    links = []\n",
    "    for p in events['partitions']:\n",
    "        links.append(p['file'])\n",
    "    return links\n",
    "\n",
    "def get_ndc_links(path):\n",
    "    \"\"\"obtain all download links for events from fdc's provided download json\"\"\"\n",
    "    with open(path, 'r') as handle:\n",
    "        file = json.load(handle)\n",
    "    events = file['results'][\"drug\"][\"ndc\"]\n",
    "    links = []\n",
    "    for p in events['partitions']:\n",
    "        links.append(p['file'])\n",
    "    return links\n",
    "\n",
    "links = get_event_links(\"download.json\")\n",
    "ndc_links = get_ndc_links(\"download.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ndc file\n",
    "url = ndc_links[0]\n",
    "infos = url.split(\"/\")[3:] # getting rid of https and website\n",
    "path = ''\n",
    "for i in infos:\n",
    "    path = os.path.join(path, i)\n",
    "    if i.endswith('.zip'):\n",
    "        break\n",
    "    else:\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        path = path.strip(\"\\n\")\n",
    "        url = url.strip(\"\\n\")\n",
    "download([url, path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21099it [00:00, 2644344.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create a symptom database from symptoms.json\"\"\"\n",
    "\n",
    "symptoms = json.load(open(\"symptoms.json\", \"r\"))\n",
    "data = {\"id\":[], \"symptom\":[]}\n",
    "for i, ele in tqdm(enumerate(symptoms)):\n",
    "    data[\"id\"].append(i)\n",
    "    data[\"symptom\"].append(ele)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(\"drug\",\"symptoms_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173528it [00:10, 16299.01it/s]\n",
      "21099it [00:01, 16336.23it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Drug and Symptom Reverse Lookup\"\"\"\n",
    "\n",
    "class Drug:\n",
    "    def __init__(self, components=None):\n",
    "        self.components = set(components) # components are lowercase strings\n",
    "    def __str__(self):\n",
    "        return ', '.join([str(x) for x in self.components])\n",
    "    def __hash__(self):\n",
    "        return hash(str(self))\n",
    "    def __len__(self):\n",
    "        return len(self.components)\n",
    "    def __list__(self):\n",
    "        return list(self.components)\n",
    "    def __eq__(self, other):\n",
    "        return self.components == other.components\n",
    "\n",
    "\n",
    "# id,brand_id,brand_name,generic_name,components,product_type,manufacturer_name\n",
    "drug_df = pd.read_csv(os.path.join(\"medicine_dataset.csv\"))\n",
    "    \n",
    "# All these drugs have a brand_name---generic_name pair and components\n",
    "# Data is clean; all lower-case\n",
    "\n",
    "brand_vocab = {}      # brand_name -> list of ids\n",
    "\n",
    "for i,row in tqdm(drug_df.iterrows()):\n",
    "    brand = row[\"brand_name\"]\n",
    "    brand_id = row[\"brand_id\"]\n",
    "    brand_vocab[brand] = brand_id\n",
    "    \n",
    "num_drugs = len(brand_vocab)\n",
    "\n",
    "# Keep track of discovered drugs\n",
    "missing_vocab = {}\n",
    "missing_drugs = {\"id\":[], \"drug_name\":[]}\n",
    "\n",
    "# Symptom -> ID\n",
    "symptom_vocab = {}\n",
    "symptom_df = pd.read_csv(os.path.join(\"drug\",\"symptoms_dataset.csv\"))\n",
    "symptom_df['symptom'] = symptom_df['symptom'].str.lower()\n",
    "for i,row in tqdm(symptom_df.iterrows()):\n",
    "    symptom_vocab[row[\"symptom\"]] = row[\"id\"]\n",
    "    \n",
    "event_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(drug_path,\"events\")):\n",
    "    os.mkdir(os.path.join(drug_path,\"events\"))\n",
    "    os.mkdir(os.path.join(drug_path,\"drugs\"))\n",
    "    os.mkdir(os.path.join(drug_path,\"characteristics\"))\n",
    "    os.mkdir(os.path.join(drug_path,\"symptoms\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "900it [2:18:08, 19.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# Drug Dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off drug_dataset\n",
    "    # missing list based off missing_dataset\n",
    "# Characterization dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off drug_dataset\n",
    "    # missing list based off missing_dataset\n",
    "# Symptoms dataset:\n",
    "    # ID (event)\n",
    "    # postings list based off symptoms_dataset\n",
    "    \n",
    "def match(val):\n",
    "    # Check if drug is a known brand name\n",
    "    if val in brand_vocab:\n",
    "        d.append(brand_vocab[val])\n",
    "        if \"drugcharacterization\" in ele: \n",
    "            d_c.append(ele[\"drugcharacterization\"])\n",
    "        else:\n",
    "            d_c.append(0)\n",
    "        return True\n",
    "\n",
    "for link_index, url in tqdm(enumerate(links)):\n",
    "    url = links[link_index]\n",
    "    # Download an event file\n",
    "    infos = url.split(\"/\")[3:] # getting rid of https and website\n",
    "    path = ''\n",
    "    for i in infos:\n",
    "        path = os.path.join(path, i)\n",
    "        if i.endswith('.zip'):\n",
    "            break\n",
    "        else:\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            path = path.strip(\"\\n\")\n",
    "            url = url.strip(\"\\n\")\n",
    "    download([url, path])\n",
    "\n",
    "    folder_name = path.split(\"\\\\\")[-2]\n",
    "    file_name = path.split(\".\")[0]\n",
    "    split_name = file_name.split(\"\\\\\")[-1]\n",
    "\n",
    "    # Grab and decode events\n",
    "    events = json.load(open(file_name+\".json\", \"r\"))\n",
    "    events = events[\"results\"]\n",
    "\n",
    "    # Event Dataset:\n",
    "    event_data = {\"ID\":[], \"sex\":[], \"age\":[], \"serious\":[], \"death\":[], \"sender\":[], \"time\":[]}\n",
    "    drug_data = {\"ID\":[], \"brands\":[], \"missing_imp\":[], \"missing_not\":[]}\n",
    "    char_data = {\"ID\":[], \"brands\":[], \"missing_imp\":[], \"missing_not\":[]}\n",
    "    symp_data = {\"ID\":[], \"symptoms\":[]}\n",
    "\n",
    "    for event in events:\n",
    "        patient = event[\"patient\"]\n",
    "\n",
    "        # Event\n",
    "        event_data[\"ID\"].append(event_id)\n",
    "        event_data[\"serious\"].append(event[\"serious\"])\n",
    "\n",
    "        if \"patientsex\" in patient:\n",
    "            event_data[\"sex\"].append(decode_sex[int(patient['patientsex'])])\n",
    "        else:\n",
    "            event_data[\"sex\"].append(0)\n",
    "        try:\n",
    "            event_data[\"age\"].append(int(patient[\"patientonsetage\"]) * to_year[patient[\"patientonsetageunit\"]])\n",
    "        except:\n",
    "            event_data[\"age\"].append(-1)\n",
    "        if \"seriousnessdeath\" in event:\n",
    "            event_data[\"death\"].append(1)\n",
    "        else:\n",
    "            event_data[\"death\"].append(0)\n",
    "        try:\n",
    "            event_data[\"sender\"].append(decode_sender[int(event[\"primarysource\"][\"qualification\"])])\n",
    "        except:\n",
    "            event_data[\"sender\"].append(0)\n",
    "        try:\n",
    "            time = event['receiptdate']\n",
    "            timestamp = datetime.datetime(int(time[0:4]), int(time[4:6]), int(time[6::]), 0, 0).timestamp()\n",
    "            event_data[\"time\"].append(timestamp)\n",
    "        except:\n",
    "            event_data[\"time\"].append(-1)\n",
    "\n",
    "        # Drugs & Characteristics\n",
    "        drug_data[\"ID\"].append(event_id)\n",
    "        char_data[\"ID\"].append(event_id)\n",
    "        d = []\n",
    "        g = []\n",
    "        d_c = []\n",
    "        g_c = []\n",
    "        \n",
    "        # Keep track of suspect / interacting drugs\n",
    "        m_d_imp = []\n",
    "        m_c_imp = []\n",
    "        \n",
    "        # Versus concomitant / unknown drugs\n",
    "        m_d_not = []\n",
    "        m_c_not = []\n",
    "        for ele in patient[\"drug\"]:\n",
    "            if \"medicinalproduct\" in ele:\n",
    "                if type(ele[\"medicinalproduct\"]) != str:\n",
    "                    continue\n",
    "                    \n",
    "                _drug = ele[\"medicinalproduct\"].lower()\n",
    "                \n",
    "                if len(re.findall(\"(unknown)|(unspecified)|(vitamin)|(inhaler)|(chewable)|(tea)\", _drug)) > 0:\n",
    "                    continue\n",
    "                \n",
    "                if not match(_drug):\n",
    "                    # Pattern 1: Split on (\n",
    "                    val = _drug.split(\"(\")[0]\n",
    "                    if match(val):\n",
    "                        continue\n",
    "                    \n",
    "                    # Patern 1.5: Split on -\n",
    "                    val = _drug.split(\"-\")[0]\n",
    "                    if match(val):\n",
    "                        continue\n",
    "                    \n",
    "                    # Pattern 2: Grab within ()\n",
    "                    val = re.findall(\"\\((.+)\\)\", _drug)\n",
    "                    if len(val) > 0:\n",
    "                        if match(val[0]):\n",
    "                            continue\n",
    "                    \n",
    "                    # Pattern 3: Drug + Drug\n",
    "                    val = re.sub(\" + \", \" and \", _drug)\n",
    "                    if match(val):\n",
    "                        continue\n",
    "                    \n",
    "                    # Pattern 4: Remove \"tablets\", \\d\\d\\d ?[um]g\n",
    "                    val = re.split(\" \\d\", _drug)[0]\n",
    "                    if match(val):\n",
    "                        continue\n",
    "                    \n",
    "                    val = re.split(\"( (?:tab)|(?:cap))\", _drug)\n",
    "                    if len(val) > 1:\n",
    "                        match(val[0])\n",
    "                        continue\n",
    "                        \n",
    "                    # ----- Drug Not Found -----\n",
    "                    \n",
    "                    # Check if this missing drug has been seen before\n",
    "                    if _drug not in missing_vocab:\n",
    "                        missing_drugs[\"id\"].append(num_drugs)\n",
    "                        missing_drugs[\"drug_name\"].append(_drug)\n",
    "                        missing_vocab[_drug] = num_drugs\n",
    "                        num_drugs += 1\n",
    "                    \n",
    "                    if \"drugcharacterization\" in ele:\n",
    "                        if ele[\"drugcharacterization\"] == \"1\" or ele[\"drugcharacterization\"] == \"3\":\n",
    "                            m_d_imp.append(missing_vocab[_drug])\n",
    "                            m_c_imp.append(ele[\"drugcharacterization\"])\n",
    "                        else:\n",
    "                            m_d_not.append(missing_vocab[_drug])\n",
    "                            m_c_not.append(ele[\"drugcharacterization\"])\n",
    "                    else:\n",
    "                        m_d_not.append(missing_vocab[_drug])\n",
    "                        m_c_not.append(0)                    \n",
    "                \n",
    "        drug_data[\"brands\"].append(\" \".join([str(x) for x in d]))\n",
    "        char_data[\"brands\"].append(\" \".join([str(x) for x in d_c]))\n",
    "        drug_data[\"missing_imp\"].append(\" \".join([str(x) for x in m_d_imp]))\n",
    "        char_data[\"missing_imp\"].append(\" \".join([str(x) for x in m_c_imp]))\n",
    "        drug_data[\"missing_not\"].append(\" \".join([str(x) for x in m_d_not]))\n",
    "        char_data[\"missing_not\"].append(\" \".join([str(x) for x in m_c_not]))\n",
    "\n",
    "        # Symptoms\n",
    "        symp_data[\"ID\"].append(event_id)\n",
    "        if \"reaction\" in patient:\n",
    "            s = []\n",
    "            for sym in patient[\"reaction\"]:\n",
    "                if \"reactionmeddrapt\" in sym:\n",
    "                    s.append(str(symptom_vocab[sym['reactionmeddrapt'].lower()]))\n",
    "            symp_data[\"symptoms\"].append(\" \".join(s))\n",
    "        else:\n",
    "            symp_data[\"symptoms\"].append(\"\")\n",
    "\n",
    "        event_id += 1\n",
    "\n",
    "    # Remove download\n",
    "    os.remove(file_name+\".json\")\n",
    "    os.rmdir(os.path.join(\"\\\\\".join(path.split(\"\\\\\")[0:3])))\n",
    "\n",
    "    # Write results to file\n",
    "    if not os.path.exists(os.path.join(drug_path,\"events\", folder_name)):\n",
    "        os.mkdir(os.path.join(drug_path,\"events\", folder_name))\n",
    "        os.mkdir(os.path.join(drug_path,\"drugs\", folder_name))\n",
    "        os.mkdir(os.path.join(drug_path,\"characteristics\", folder_name))\n",
    "        os.mkdir(os.path.join(drug_path,\"symptoms\", folder_name))\n",
    "\n",
    "    event_df = pd.DataFrame(event_data)\n",
    "    event_df.to_csv(os.path.join(drug_path, \"events\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    drug_df = pd.DataFrame(drug_data)\n",
    "    drug_df.to_csv(os.path.join(drug_path, \"drugs\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    char_df = pd.DataFrame(char_data)\n",
    "    char_df.to_csv(os.path.join(drug_path, \"characteristics\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "    symp_df = pd.DataFrame(symp_data)\n",
    "    symp_df.to_csv(os.path.join(drug_path, \"symptoms\", folder_name, split_name+\".csv\"), index=False)\n",
    "\n",
    "missing_df = pd.DataFrame(missing_drugs)\n",
    "missing_df.to_csv(os.path.join(drug_path,\"missing_drugs_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num missing: 477831\n",
      "num events: 10432358\n"
     ]
    }
   ],
   "source": [
    "print(\"num missing:\", len(missing_drugs[\"drug_name\"]))\n",
    "print(\"num events:\", event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [01:59<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "df = None\n",
    "check = False\n",
    "for folder in tqdm(os.listdir(os.path.join(drug_path, \"drugs\"))):\n",
    "    for file in os.listdir(os.path.join(drug_path, \"drugs\", folder)):\n",
    "        if check:\n",
    "            df = pd.concat([df, pd.read_csv(os.path.join(drug_path, \"drugs\", folder, file))])\n",
    "        else:\n",
    "            df = pd.read_csv(os.path.join(drug_path, \"drugs\", folder, file))\n",
    "            check = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2742121\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(\"\")\n",
    "subset = df.loc[df[\"missing_imp\"]==\"\"]\n",
    "subset = subset[subset[\"brands\"]!=\"\"]\n",
    "subset = subset[subset[\"brands\"].str.contains(\" \")]\n",
    "subset = subset[[\"ID\",\"brands\"]]\n",
    "print(len(subset))\n",
    "subset.to_csv(os.path.join(drug_path,\"no_missing_drugs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2742121it [02:41, 16967.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 5521/5521 [00:00<00:00, 1845306.59it/s]\n"
     ]
    }
   ],
   "source": [
    "drug_count = {}\n",
    "for i, row in tqdm(subset.iterrows()):\n",
    "    b = row[\"brands\"].split(\" \")\n",
    "    for ele in b:\n",
    "        if ele not in drug_count:\n",
    "            drug_count[ele] = 0\n",
    "        drug_count[ele] += 1\n",
    "        \n",
    "counts = {\"id\":[], \"count\":[]}\n",
    "for ele in tqdm(drug_count):\n",
    "    counts[\"id\"].append(ele)\n",
    "    counts[\"count\"].append(drug_count[ele])\n",
    "sup_df = pd.DataFrame.from_dict(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5521\n",
      "1415\n"
     ]
    }
   ],
   "source": [
    "print(len(sup_df))\n",
    "print(len(sup_df.loc[sup_df[\"count\"]>len(sup_df)*0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2742121it [03:05, 14749.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2523823\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "basket_size = {}\n",
    "minsup = sup_df.loc[sup_df[\"count\"]>len(sup_df)*0.1]\n",
    "#minsup = sup_df.loc[sup_df[\"count\"]>10000]\n",
    "for i, row in minsup.iterrows():\n",
    "    vocab[row[\"id\"]] = row[\"count\"]\n",
    "out_data = {\"ID\":[], \"brands\":[]}\n",
    "\n",
    "#for i, row in tqdm(subset.iterrows()):\n",
    "#    b = row[\"brands\"].split(\" \")\n",
    "#    if len(b) not in basket_size:\n",
    "#        basket_size[len(b)] = 0\n",
    "#    basket_size[len(b)] += 1\n",
    "    \n",
    "for i, row in tqdm(subset.iterrows()):\n",
    "    b = row[\"brands\"].split(\" \")\n",
    "    #if basket_size[len(b)] > 1000:\n",
    "    #    continue\n",
    "    check = True\n",
    "    for ele in b:\n",
    "        if ele not in vocab:\n",
    "            check = False\n",
    "            break\n",
    "    if check:\n",
    "        out_data[\"ID\"].append(row[\"ID\"])\n",
    "        out_data[\"brands\"].append(row[\"brands\"])\n",
    "test_df = pd.DataFrame.from_dict(out_data)\n",
    "print(len(test_df))\n",
    "test_df.to_csv(os.path.join(drug_path,\"no_missing_drugs_minsup_1.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
